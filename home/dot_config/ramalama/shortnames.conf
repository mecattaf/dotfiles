# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”– RAMALAMA SHORTNAMES CONFIGURATION
# Generated by Chezmoi - DO NOT EDIT MANUALLY
# Auto-generated from .chezmoi.yaml.tmpl â†’ local_inference.models
# Location: ~/.config/ramalama/shortnames.conf
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Shortnames allow you to use simple aliases instead of full URIs
# Example: ramalama run granite â†’ ramalama run ollama://granite3.1-dense:8b

[shortnames]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LOCAL INFERENCE MODELS (from .chezmoi.yaml.tmpl)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"gpt_oss_20b" = "huggingface://openai/gpt-oss-20b-GGUF/gpt-oss-20b-q4_k_m.gguf"
"gpt_oss_120b" = "huggingface://openai/gpt-oss-120b-GGUF/gpt-oss-120b-q4_k_m.gguf"
"qwen3-tiny" = "huggingface://Qwen/Qwen3-0.6B-GGUF/qwen3-0.6b-q4_k_m.gguf"
"qwen3-medium" = "huggingface://Qwen/Qwen3-4B-GGUF/qwen3-4b-q4_k_m.gguf"
"qwen3-emb-large" = "huggingface://Qwen/Qwen3-Embedding-8B-GGUF/qwen3-embedding-8b-q8_0.gguf"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“ USAGE NOTES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# This file is auto-generated from .chezmoi.yaml.tmpl
# To add/remove shortnames, edit the local_inference.models section there
#
# USAGE EXAMPLES:
#   ramalama run gpt_oss_20b
#   ramalama pull gpt_oss_20b
#   ramalama run gpt_oss_120b
#   ramalama pull gpt_oss_120b
#   ramalama run qwen3-tiny
#   ramalama pull qwen3-tiny
#   ramalama run qwen3-medium
#   ramalama pull qwen3-medium
#   ramalama run qwen3-emb-large
#   ramalama pull qwen3-emb-large
#
# MANUAL SHORTNAMES:
# You can also add custom shortnames not managed by chezmoi
# by editing this file directly (they will be preserved)
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#"granite" = "ollama://granite3.1-dense:8b"
#"qwen" = "huggingface://Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m.gguf"
#"tiny" = "ollama://tinyllama"
#"codellama" = "ollama://codellama:13b"
#
