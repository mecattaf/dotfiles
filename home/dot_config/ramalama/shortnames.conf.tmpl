# ═════════════════════════════════════════════════════════════════════════════
# 🔖 RAMALAMA SHORTNAMES CONFIGURATION
# Generated by Chezmoi - DO NOT EDIT MANUALLY
# Auto-generated from .chezmoi.yaml.tmpl → local_inference.models
# Location: ~/.config/ramalama/shortnames.conf
# ═════════════════════════════════════════════════════════════════════════════

# Shortnames allow you to use simple aliases instead of full URIs
# Example: ramalama run granite → ramalama run ollama://granite3.1-dense:8b

[shortnames]

# ─────────────────────────────────────────────────────────────────────────────
# LOCAL INFERENCE MODELS (from .chezmoi.yaml.tmpl)
# ─────────────────────────────────────────────────────────────────────────────
{{- range $key, $model := .local_inference.models }}
{{- if $model.enabled }}
"{{ $model.shortname | default $key }}" = "{{ $model.model_uri }}"
{{- end }}
{{- end }}

# ═════════════════════════════════════════════════════════════════════════════
# 📝 USAGE NOTES
# ═════════════════════════════════════════════════════════════════════════════
#
# This file is auto-generated from .chezmoi.yaml.tmpl
# To add/remove shortnames, edit the local_inference.models section there
#
# USAGE EXAMPLES:
{{- range $key, $model := .local_inference.models }}
{{- if $model.enabled }}
#   ramalama run {{ $model.shortname | default $key }}
#   ramalama pull {{ $model.shortname | default $key }}
{{- end }}
{{- end }}
#
# MANUAL SHORTNAMES:
# You can also add custom shortnames not managed by chezmoi
# by editing this file directly (they will be preserved)
#
# ═════════════════════════════════════════════════════════════════════════════
#
#"granite" = "ollama://granite3.1-dense:8b"
#"qwen" = "huggingface://Qwen/Qwen2.5-7B-Instruct-GGUF/qwen2.5-7b-instruct-q4_k_m.gguf"
#"tiny" = "ollama://tinyllama"
#"codellama" = "ollama://codellama:13b"
